{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# install\n"
      ],
      "metadata": {
        "id": "StvQ3FFetoN3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lia0IIRSodFB",
        "outputId": "59cd5bda-d894-4639-8228-263321c6f6e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Fri Nov 18 11:17:37 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8    10W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "    !nvidia-smi\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.12.2\n",
        "!pip install farasapy==0.0.14\n",
        "!pip install pyarabic==0.6.14\n",
        "!git clone https://github.com/aub-mind/arabert\n",
        "!pip install emoji==1.6.1\n",
        "!pip install sentencepiece==0.1.96"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2ZUSLO9ogVe",
        "outputId": "24f35ddc-1ad6-4765-d1e9-2a8c37be61d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.12.2\n",
            "  Downloading transformers-4.12.2-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 31.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.2) (4.64.1)\n",
            "Collecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 64.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.2) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.2) (3.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.2) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 61.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.2) (21.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 44.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.2) (4.13.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.2) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.2) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers==4.12.2) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.12.2) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.12.2) (3.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.12.2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.12.2) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.12.2) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.12.2) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.12.2) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.12.2) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.12.2) (1.2.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895259 sha256=eee747d3a057a374f62e56b3b3baa6a22cd36f9c021041fc90bd8b54e4e117da\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.0 sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.12.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting farasapy==0.0.14\n",
            "  Downloading farasapy-0.0.14-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from farasapy==0.0.14) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from farasapy==0.0.14) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy==0.0.14) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy==0.0.14) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy==0.0.14) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy==0.0.14) (3.0.4)\n",
            "Installing collected packages: farasapy\n",
            "Successfully installed farasapy-0.0.14\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyarabic==0.6.14\n",
            "  Downloading PyArabic-0.6.14-py3-none-any.whl (126 kB)\n",
            "\u001b[K     |████████████████████████████████| 126 kB 28.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from pyarabic==0.6.14) (1.15.0)\n",
            "Installing collected packages: pyarabic\n",
            "Successfully installed pyarabic-0.6.14\n",
            "Cloning into 'arabert'...\n",
            "remote: Enumerating objects: 600, done.\u001b[K\n",
            "remote: Counting objects: 100% (65/65), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 600 (delta 38), reused 45 (delta 30), pack-reused 535\u001b[K\n",
            "Receiving objects: 100% (600/600), 9.14 MiB | 5.38 MiB/s, done.\n",
            "Resolving deltas: 100% (339/339), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting emoji==1.6.1\n",
            "  Downloading emoji-1.6.1.tar.gz (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 34.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.6.1-py3-none-any.whl size=169313 sha256=737b416639b27b4d5921262e56d295f237e23c00295cbec4f087a396d9a2d9fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/5f/d3/03d313ddb3c2a1a427bb4690f1621eea60fe6f2a30cc95940f\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-1.6.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece==0.1.96\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 32.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import List\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "9qqVKNUzowHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# dataset"
      ],
      "metadata": {
        "id": "Ofwqh0obtz44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset:\n",
        "    def __init__(\n",
        "        self,\n",
        "        name: str,\n",
        "        train: List[pd.DataFrame],\n",
        "        test: List[pd.DataFrame],\n",
        "        label_list: List[str],\n",
        "    ):\n",
        "        \"\"\"Class to hold and structure datasets.\n",
        "\n",
        "        Args:\n",
        "\n",
        "        name (str): holds the name of the dataset so we can select it later\n",
        "        train (List[pd.DataFrame]): holds training pandas dataframe with 2 columns [\"text\",\"label\"]\n",
        "        test (List[pd.DataFrame]): holds testing pandas dataframe with 2 columns [\"text\",\"label\"]\n",
        "        label_list (List[str]): holds the list  of labels\n",
        "        \"\"\"\n",
        "        self.name = name\n",
        "        self.train = train\n",
        "        self.test = test\n",
        "        self.label_list = label_list"
      ],
      "metadata": {
        "id": "4K6hFn5ipBJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This will hold all the downloaded and structred datasets\n",
        "all_datasets= []\n",
        "DATA_COLUMN = \"text\"\n",
        "LABEL_COLUMN = \"label\""
      ],
      "metadata": {
        "id": "yvo-6znvpGpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ailments_data = pd.read_excel('ailments_arabic.xlsx',header = None)\n",
        "ailments_data.rename(columns = {0:'phrase', 1:'prompt'}, inplace = True)\n",
        "\n",
        "\n",
        "ailments_data.columns = [DATA_COLUMN, LABEL_COLUMN]\n",
        "print(ailments_data[LABEL_COLUMN].value_counts())\n",
        "\n",
        "label_list = list(ailments_data[LABEL_COLUMN].unique())\n",
        "\n",
        "ailments_data[LABEL_COLUMN] = ailments_data[LABEL_COLUMN].astype('category')\n",
        "\n",
        "ailments_data[LABEL_COLUMN] = ailments_data[LABEL_COLUMN].cat.codes\n",
        "ailments_data\n",
        "\n",
        "\n",
        "train, test = train_test_split(ailments_data, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "data = CustomDataset(\"ailments_data\", train, test, label_list)\n",
        "# # all_datasets.append(data_Hard)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkgFemG7pMdJ",
        "outputId": "172a890c-e469-433d-b4e9-fb1864ffbec6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flu           31\n",
            "Anemia        28\n",
            "Stress        23\n",
            "Allergy       21\n",
            "Fatigue       20\n",
            "Bronchitis    17\n",
            "Diarrhea      12\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3JSfJGODt-LK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train"
      ],
      "metadata": {
        "id": "L254zEtkt_nQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "from arabert.preprocess import ArabertPreprocessor\n",
        "from sklearn.metrics import (accuracy_score, classification_report,\n",
        "                             confusion_matrix, f1_score, precision_score,\n",
        "                             recall_score)\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import (AutoConfig, AutoModelForSequenceClassification,\n",
        "                          AutoTokenizer, BertTokenizer, Trainer,\n",
        "                          TrainingArguments)\n",
        "from transformers.data.processors.utils import InputFeatures"
      ],
      "metadata": {
        "id": "h6buEohUuD_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# select a model from the huggingface modelhub https://huggingface.co/models?language=ar\n",
        "model_name = 'Ammar-alhaj-ali/arabic-MARBERT-dialect-identification-city' # we are going to use the twitter AraBERT since it has emojis and dialects"
      ],
      "metadata": {
        "id": "q3qJIgnjuHfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arabic_prep = ArabertPreprocessor(model_name)\n",
        "\n",
        "data.train[DATA_COLUMN] = data.train[DATA_COLUMN].apply(lambda x: arabic_prep.preprocess(x))\n",
        "data.test[DATA_COLUMN] = data.test[DATA_COLUMN].apply(lambda x: arabic_prep.preprocess(x))  "
      ],
      "metadata": {
        "id": "lqFcta6wuT4B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6719db25-73e6-4734-de05-23d14fed35dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Model provided is not in the accepted model list. Preprocessor will default to a base Arabic preprocessor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(data.train[DATA_COLUMN][0:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wV2UX3ecuyWz",
        "outputId": "daa95d3d-8c0d-40bf-9b42-7caeb9f974a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['لدي الأظافر البيضاء',\n",
              " 'لدي الصداع ، والدوخة ، وطنين في الأذنين',\n",
              " 'أنا لا أستطيع التنفس',\n",
              " 'لدي بشرة الجافة جدا',\n",
              " 'لدي طفح جلدي',\n",
              " 'لدي العرق البارد',\n",
              " 'لدي صداع',\n",
              " 'أسعل',\n",
              " 'أنا جائع جدا ولكن ليس لدي شهية',\n",
              " 'أريد أن أنام ، أنا نعسان']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tok = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vVPmk3Xu0iB",
        "outputId": "3e96d00b-48d4-4939-d02a-9517ad6c1ce1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/Ammar-alhaj-ali/arabic-MARBERT-dialect-identification-city/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/69290462745b1865dac00fbd2b0279a10cba09c40f032fc91e779b222fe7fe97.9985cd6ca030442c4f68221160381b229fee63902f75a8f43e14e78007536585\n",
            "loading file https://huggingface.co/Ammar-alhaj-ali/arabic-MARBERT-dialect-identification-city/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/e8a327f7653443a2e68232e7ace452fcbc0b32feca96916c7417fc10ec187de8.c45a0acbaab52f14cb775dbc8f96269b8448af78e79b7ffe7ea1aee9af1c3d30\n",
            "loading file https://huggingface.co/Ammar-alhaj-ali/arabic-MARBERT-dialect-identification-city/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/Ammar-alhaj-ali/arabic-MARBERT-dialect-identification-city/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/12738ae0a8fd10ad2711e0257b3a28e75a7d1101fc188c285891f543ea53eb9d.7da70648c6cb9951e284c9685f9ba7ae083dd59ed1d6d84bdfc0584a4ea94b6d\n",
            "loading file https://huggingface.co/Ammar-alhaj-ali/arabic-MARBERT-dialect-identification-city/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/7c9d9a36d71d5419a2bb1531274561fc439919fbfb075de8e6ac0fef2d3a5b3b.8b1b1ce0403e3f9fe50e5f8fb2084d13154de1c54a7673a0831ece3ead7279fc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Sentence Lengths: \")\n",
        "plt.hist([ len(tok.tokenize(sentence)) for sentence in data.train[DATA_COLUMN].to_list()],bins=range(0,128,2))\n",
        "plt.show()\n",
        "\n",
        "print(\"Testing Sentence Lengths: \")\n",
        "plt.hist([ len(tok.tokenize(sentence)) for sentence in data.test[DATA_COLUMN].to_list()],bins=range(0,128,2))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "_5KLQzJrvj6A",
        "outputId": "82999a24-7b26-42bb-d03b-48529696608a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Sentence Lengths: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Sentence Lengths: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max([ len(tok.tokenize(sentence)) for sentence in data.test[DATA_COLUMN].to_list()])\n",
        "max([ len(tok.tokenize(sentence)) for sentence in data.train[DATA_COLUMN].to_list()])\n",
        "\n",
        "max_len=25"
      ],
      "metadata": {
        "id": "UqsDHu-uTMLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Truncated training sequences: \", sum([len(tok.tokenize(sentence)) > max_len for sentence in data.train[DATA_COLUMN].to_list()]))\n",
        "\n",
        "print(\"Truncated testing sequences: \", sum([len(tok.tokenize(sentence)) > max_len for sentence in data.test[DATA_COLUMN].to_list()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxzJYaFpTas8",
        "outputId": "6748a15f-c2d5-4e28-b26d-263b21e76258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Truncated training sequences:  0\n",
            "Truncated testing sequences:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassificationDataset(Dataset):\n",
        "    def __init__(self, text, target, model_name, max_len, label_map):\n",
        "      super(ClassificationDataset).__init__()\n",
        "      \"\"\"\n",
        "      Args:\n",
        "      text (List[str]): List of the training text\n",
        "      target (List[str]): List of the training labels\n",
        "      tokenizer_name (str): The tokenizer name (same as model_name).\n",
        "      max_len (int): Maximum sentence length\n",
        "      label_map (Dict[str,int]): A dictionary that maps the class labels to integer\n",
        "      \"\"\"\n",
        "      self.text = text\n",
        "      self.target = target\n",
        "      self.tokenizer_name = model_name\n",
        "      self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "      self.max_len = max_len\n",
        "      self.label_map = label_map\n",
        "      \n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.text)\n",
        "\n",
        "    def __getitem__(self,item):\n",
        "      text = str(self.text[item])\n",
        "      text = \" \".join(text.split())\n",
        "        \n",
        "      inputs = self.tokenizer(\n",
        "          text,\n",
        "          max_length=self.max_len,\n",
        "          padding='max_length',\n",
        "          truncation=True\n",
        "      )      \n",
        "      return InputFeatures(**inputs,label=self.label_map[self.target[item]])"
      ],
      "metadata": {
        "id": "IGKeGgATTxr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = { v:index for index, v in enumerate(data.label_list) }\n",
        "print(label_map)\n",
        "\n",
        "train_dataset = ClassificationDataset(\n",
        "    data.train[DATA_COLUMN].to_list(),\n",
        "    data.train[LABEL_COLUMN].to_list(),\n",
        "    model_name,\n",
        "    max_len,\n",
        "    label_map\n",
        "  )\n",
        "test_dataset = ClassificationDataset(\n",
        "    data.test[DATA_COLUMN].to_list(),\n",
        "    data.test[LABEL_COLUMN].to_list(),\n",
        "    model_name,\n",
        "    max_len,\n",
        "    label_map\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrHfEiRpUqnF",
        "outputId": "a3e31d29-3497-4b32-afa6-32f2464e5eff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Allergy': 0, 'Anemia': 1, 'Bronchitis': 2, 'Diarrhea': 3, 'Fatigue': 4, 'Flu': 5, 'Stress': 6}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/Ammar-alhaj-ali/arabic-MARBERT-dialect-identification-city/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/69290462745b1865dac00fbd2b0279a10cba09c40f032fc91e779b222fe7fe97.9985cd6ca030442c4f68221160381b229fee63902f75a8f43e14e78007536585\n",
            "loading file https://huggingface.co/Ammar-alhaj-ali/arabic-MARBERT-dialect-identification-city/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/e8a327f7653443a2e68232e7ace452fcbc0b32feca96916c7417fc10ec187de8.c45a0acbaab52f14cb775dbc8f96269b8448af78e79b7ffe7ea1aee9af1c3d30\n",
            "loading file https://huggingface.co/Ammar-alhaj-ali/arabic-MARBERT-dialect-identification-city/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/Ammar-alhaj-ali/arabic-MARBERT-dialect-identification-city/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/12738ae0a8fd10ad2711e0257b3a28e75a7d1101fc188c285891f543ea53eb9d.7da70648c6cb9951e284c9685f9ba7ae083dd59ed1d6d84bdfc0584a4ea94b6d\n",
            "loading file https://huggingface.co/Ammar-alhaj-ali/arabic-MARBERT-dialect-identification-city/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/7c9d9a36d71d5419a2bb1531274561fc439919fbfb075de8e6ac0fef2d3a5b3b.8b1b1ce0403e3f9fe50e5f8fb2084d13154de1c54a7673a0831ece3ead7279fc\n",
            "loading file https://huggingface.co/Ammar-alhaj-ali/arabic-MARBERT-dialect-identification-city/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/69290462745b1865dac00fbd2b0279a10cba09c40f032fc91e779b222fe7fe97.9985cd6ca030442c4f68221160381b229fee63902f75a8f43e14e78007536585\n",
            "loading file https://huggingface.co/Ammar-alhaj-ali/arabic-MARBERT-dialect-identification-city/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/e8a327f7653443a2e68232e7ace452fcbc0b32feca96916c7417fc10ec187de8.c45a0acbaab52f14cb775dbc8f96269b8448af78e79b7ffe7ea1aee9af1c3d30\n",
            "loading file https://huggingface.co/Ammar-alhaj-ali/arabic-MARBERT-dialect-identification-city/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/Ammar-alhaj-ali/arabic-MARBERT-dialect-identification-city/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/12738ae0a8fd10ad2711e0257b3a28e75a7d1101fc188c285891f543ea53eb9d.7da70648c6cb9951e284c9685f9ba7ae083dd59ed1d6d84bdfc0584a4ea94b6d\n",
            "loading file https://huggingface.co/Ammar-alhaj-ali/arabic-MARBERT-dialect-identification-city/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/7c9d9a36d71d5419a2bb1531274561fc439919fbfb075de8e6ac0fef2d3a5b3b.8b1b1ce0403e3f9fe50e5f8fb2084d13154de1c54a7673a0831ece3ead7279fc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(next(iter(train_dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "fd-pgg-GUrTP",
        "outputId": "9b238af5-1b6c-4355-f11c-c5029b4deedb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-1ec4c0bdb629>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-62-70f69fcbc36f>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     31\u001b[0m           \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m       )      \n\u001b[0;32m---> 33\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mInputFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(label_map)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U2Hi8BCU0-d",
        "outputId": "cf8df8f6-eba7-43c3-f2c6-32f00a6cd0cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_init():\n",
        "    return AutoModelForSequenceClassification.from_pretrained(model_name, return_dict=True, num_labels=len(label_map))"
      ],
      "metadata": {
        "id": "G9GkBAaXVFI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(p): #p should be of type EvalPrediction\n",
        "  preds = np.argmax(p.predictions, axis=1)\n",
        "  assert len(preds) == len(p.label_ids)\n",
        "  #print(classification_report(p.label_ids,preds))\n",
        "  #print(confusion_matrix(p.label_ids,preds))\n",
        "  macro_f1 = f1_score(p.label_ids,preds,average='macro')\n",
        "  #macro_precision = precision_score(p.label_ids,preds,average='macro')\n",
        "  #macro_recall = recall_score(p.label_ids,preds,average='macro')\n",
        "  acc = accuracy_score(p.label_ids,preds)\n",
        "  return {       \n",
        "      'macro_f1' : macro_f1,\n",
        "      'accuracy': acc\n",
        "  }"
      ],
      "metadata": {
        "id": "yTMW2jYDV9ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed=42):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  torch.backends.cudnn.deterministic=True\n",
        "  torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "faYfr3xEWDGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments( \n",
        "    output_dir= \"./train\",    \n",
        "    adam_epsilon = 1e-8,\n",
        "    learning_rate = 2e-5,\n",
        "    fp16 = False, # enable this when using V100 or T4 GPU\n",
        "    per_device_train_batch_size = 16, # up to 64 on 16GB with max len of 128\n",
        "    per_device_eval_batch_size = 128,\n",
        "    gradient_accumulation_steps = 2, # use this to scale batch size without needing more memory\n",
        "    num_train_epochs= 2,\n",
        "    warmup_ratio = 0,\n",
        "    do_eval = True,\n",
        "    evaluation_strategy = 'epoch',\n",
        "    save_strategy = 'epoch',\n",
        "    load_best_model_at_end = True, # this allows to automatically get the best model at the end based on whatever metric we want\n",
        "    metric_for_best_model = 'macro_f1',\n",
        "    greater_is_better = True,\n",
        "    seed = 25\n",
        "  )\n",
        "\n",
        "set_seed(training_args.seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-by02dMOWG2S",
        "outputId": "0fff130a-d6de-4891-dae3-b0abe7deac88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model = model_init(),\n",
        "    args = training_args,\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w46G8wBpWN0g",
        "outputId": "0ff1418c-42b2-40de-9729-0cf6bdb9565b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/Ammar-alhaj-ali/arabic-MARBERT-dialect-identification-city/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/91e8d6169e360dbb82e1011844a0a4e328c9a371275c4145f4ff7154613af8ac.337289b35831d3b14be2112c7bbcc35339dc0f4265ff61051cf4098d1711d799\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"UBC-NLP/MARBERT\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\",\n",
            "    \"6\": \"LABEL_6\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5,\n",
            "    \"LABEL_6\": 6\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 100000\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/Ammar-alhaj-ali/arabic-MARBERT-dialect-identification-city/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/c73cee6adeed5ded77c62eaae8f604da27305f534f0227b84ff7350422a518cf.884e8148a3b94089f966f9d5bda856e234fdfd4dc24640059e61821cf2741a38\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-96e867af74e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer = Trainer(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-72-cd1fab5c2cdc>\u001b[0m in \u001b[0;36mmodel_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m         raise ValueError(\n\u001b[1;32m    421\u001b[0m             \u001b[0;34mf\"Unrecognized configuration class {config.__class__} for this kind of AutoModel: {cls.__name__}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1444\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m                     \u001b[0mignore_mismatched_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_mismatched_sizes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1446\u001b[0;31m                     \u001b[0m_fast_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fast_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1447\u001b[0m                 )\n\u001b[1;32m   1448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_state_dict_into_model\u001b[0;34m(cls, model, state_dict, pretrained_model_name_or_path, ignore_mismatched_sizes, _fast_init)\u001b[0m\n\u001b[1;32m   1593\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0merror_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error(s) in loading state_dict for {model.__class__.__name__}:\\n\\t{error_msg}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BertForSequenceClassification:\n\tsize mismatch for classifier.weight: copying a param with shape torch.Size([26, 768]) from checkpoint, the shape in current model is torch.Size([7, 768]).\n\tsize mismatch for classifier.bias: copying a param with shape torch.Size([26]) from checkpoint, the shape in current model is torch.Size([7])."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#start the training\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "TLfKZRPjWQtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_init()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DUD5AK2JWj8w",
        "outputId": "f1f451c7-09bf-4bcd-dc76-d64a6cc5f639"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/Ammar-alhaj-ali/arabic-MARBERT-dialect-identification-city/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/91e8d6169e360dbb82e1011844a0a4e328c9a371275c4145f4ff7154613af8ac.337289b35831d3b14be2112c7bbcc35339dc0f4265ff61051cf4098d1711d799\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"UBC-NLP/MARBERT\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\",\n",
            "    \"6\": \"LABEL_6\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5,\n",
            "    \"LABEL_6\": 6\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 100000\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/Ammar-alhaj-ali/arabic-MARBERT-dialect-identification-city/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/c73cee6adeed5ded77c62eaae8f604da27305f534f0227b84ff7350422a518cf.884e8148a3b94089f966f9d5bda856e234fdfd4dc24640059e61821cf2741a38\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-c051ff6d0004>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-72-cd1fab5c2cdc>\u001b[0m in \u001b[0;36mmodel_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m         raise ValueError(\n\u001b[1;32m    421\u001b[0m             \u001b[0;34mf\"Unrecognized configuration class {config.__class__} for this kind of AutoModel: {cls.__name__}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1444\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m                     \u001b[0mignore_mismatched_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_mismatched_sizes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1446\u001b[0;31m                     \u001b[0m_fast_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fast_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1447\u001b[0m                 )\n\u001b[1;32m   1448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_state_dict_into_model\u001b[0;34m(cls, model, state_dict, pretrained_model_name_or_path, ignore_mismatched_sizes, _fast_init)\u001b[0m\n\u001b[1;32m   1593\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0merror_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error(s) in loading state_dict for {model.__class__.__name__}:\\n\\t{error_msg}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BertForSequenceClassification:\n\tsize mismatch for classifier.weight: copying a param with shape torch.Size([26, 768]) from checkpoint, the shape in current model is torch.Size([7, 768]).\n\tsize mismatch for classifier.bias: copying a param with shape torch.Size([26]) from checkpoint, the shape in current model is torch.Size([7])."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6dR-To6-aro3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}